name: Build, Push, and Deploy

on:
  push:
    branches: [ "main" ]
  workflow_dispatch:

env:
  REGISTRY: ghcr.io

jobs:
  build-and-push:
    name: Build and push images
    runs-on: ubuntu-latest
    permissions:
      contents: read
      packages: write # allow pushing to GHCR
    outputs:
      image_web: ${{ steps.vars.outputs.image_web }}
      image_api: ${{ steps.vars.outputs.image_api }}
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Log in to GHCR
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Compute dynamic image names
        id: vars
        shell: bash
        run: |
          OWNER_LC="${GITHUB_REPOSITORY_OWNER,,}"
          REPO_NAME="${GITHUB_REPOSITORY##*/}"
          REPO_LC="${REPO_NAME,,}"
          echo "owner_lc=$OWNER_LC" >> $GITHUB_OUTPUT
          echo "repo_lc=$REPO_LC" >> $GITHUB_OUTPUT
          echo "image_web=ghcr.io/$OWNER_LC/$REPO_LC-web" >> $GITHUB_OUTPUT
          echo "image_api=ghcr.io/$OWNER_LC/$REPO_LC-api" >> $GITHUB_OUTPUT

      - name: Build and push WEB image
        uses: docker/build-push-action@v6
        with:
          context: .
          file: client/Dockerfile
          push: true
          build-args: |
            VITE_API_BASE_URL=/api
          tags: |
            ${{ steps.vars.outputs.image_web }}:latest
            ${{ steps.vars.outputs.image_web }}:${{ github.sha }}

      - name: Build and push API image
        uses: docker/build-push-action@v6
        with:
          context: .
          file: server/Dockerfile
          push: true
          tags: |
            ${{ steps.vars.outputs.image_api }}:latest
            ${{ steps.vars.outputs.image_api }}:${{ github.sha }}

  deploy:
    name: Deploy to VPS
    needs: build-and-push
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Prepare deployment artifacts (compose + caddy)
        uses: actions/upload-artifact@v4
        with:
          name: compose-prod
          path: |
            docker-compose.prod.yml
            docker-compose.prod.https.yml
            deploy/caddy/Caddyfile

      - name: Download docker-compose on runner
        uses: actions/download-artifact@v4
        with:
          name: compose-prod
          path: ./deploy-artifacts

      - name: Copy deployment files to VPS
        uses: appleboy/scp-action@v0.1.7
        with:
          host: ${{ secrets.VPS_HOST }}
          username: ${{ secrets.VPS_USER }}
          key: ${{ secrets.VPS_SSH_KEY }}
          source: |
            deploy-artifacts/docker-compose.prod.yml
            deploy-artifacts/docker-compose.prod.https.yml
            deploy-artifacts/deploy/caddy/Caddyfile
          target: ${{ secrets.VPS_APP_DIR }}
          strip_components: 1

      - name: Deploy over SSH
        uses: appleboy/ssh-action@v1.0.3
        with:
          host: ${{ secrets.VPS_HOST }}
          username: ${{ secrets.VPS_USER }}
          key: ${{ secrets.VPS_SSH_KEY }}
          script_stop: true
          script: |
            set -e
            APP_DIR=${{ secrets.VPS_APP_DIR }}
            mkdir -p "$APP_DIR"
            cd "$APP_DIR"

            # Optional: write/update .env with DB URL or CORS, if provided as secrets
            if [ -n "${{ secrets.API_DATABASE_URL }}" ]; then
              grep -q '^DATABASE_URL=' .env 2>/dev/null && sed -i "s|^DATABASE_URL=.*$|DATABASE_URL=${{ secrets.API_DATABASE_URL }}|" .env || echo "DATABASE_URL=${{ secrets.API_DATABASE_URL }}" >> .env
            fi
            if [ -n "${{ secrets.API_CORS_ORIGIN }}" ]; then
              grep -q '^CORS_ORIGIN=' .env 2>/dev/null && sed -i "s|^CORS_ORIGIN=.*$|CORS_ORIGIN=${{ secrets.API_CORS_ORIGIN }}|" .env || echo "CORS_ORIGIN=${{ secrets.API_CORS_ORIGIN }}" >> .env
            fi

            # Optional: write/update HTTPS domain/email if provided
            if [ -n "${{ secrets.CADDY_DOMAIN }}" ]; then
              grep -q '^CADDY_DOMAIN=' .env 2>/dev/null && sed -i "s|^CADDY_DOMAIN=.*$|CADDY_DOMAIN=${{ secrets.CADDY_DOMAIN }}|" .env || echo "CADDY_DOMAIN=${{ secrets.CADDY_DOMAIN }}" >> .env
            fi
            if [ -n "${{ secrets.CADDY_EMAIL }}" ]; then
              grep -q '^CADDY_EMAIL=' .env 2>/dev/null && sed -i "s|^CADDY_EMAIL=.*$|CADDY_EMAIL=${{ secrets.CADDY_EMAIL }}|" .env || echo "CADDY_EMAIL=${{ secrets.CADDY_EMAIL }}" >> .env
            fi

            # Login to GHCR to pull images (uses PAT if provided, else GITHUB_TOKEN)
            GHCR_USER="${{ secrets.GHCR_READ_USERNAME }}"
            GHCR_TOKEN="${{ secrets.GHCR_READ_TOKEN }}"
            if [ -z "$GHCR_USER" ]; then GHCR_USER="${{ github.actor }}"; fi
            if [ -z "$GHCR_TOKEN" ]; then GHCR_TOKEN="${{ secrets.GITHUB_TOKEN }}"; fi
            echo "$GHCR_TOKEN" | docker login ghcr.io -u "$GHCR_USER" --password-stdin

            # Export dynamic image names for compose substitution
            export IMAGE_WEB='${{ needs.build-and-push.outputs.image_web }}:latest'
            export IMAGE_API='${{ needs.build-and-push.outputs.image_api }}:latest'

            echo "Pulling and restarting stack..."
            COMPOSE_FILES="-f docker-compose.prod.yml"
            if grep -q '^CADDY_DOMAIN=' .env && grep -q '^CADDY_EMAIL=' .env; then
              if [ -f docker-compose.prod.https.yml ]; then
                COMPOSE_FILES="-f docker-compose.prod.yml -f docker-compose.prod.https.yml"
                echo "HTTPS enabled via Caddy for domain $(grep '^CADDY_DOMAIN=' .env | cut -d'=' -f2)"
              fi
            fi
            docker compose $COMPOSE_FILES --env-file .env pull
            docker compose $COMPOSE_FILES --env-file .env up -d

            echo "Pruning old images..."
            docker image prune -f

            # Install/refresh daily PostgreSQL backups at 02:00
            mkdir -p "$APP_DIR/backups" "$APP_DIR/bin" "$APP_DIR/deploy/caddy"
            cat > "$APP_DIR/bin/pg_backup.sh" << 'EOF'
            #!/usr/bin/env bash
            set -euo pipefail
            TS=$(date +%F-%H%M%S)
            OUT_DIR="$HOME/aitesting/backups"
            mkdir -p "$OUT_DIR"
            # Use docker exec to dump from the postgres container
            docker exec lectio-postgres pg_dump -U postgres lectio_mvp | gzip > "$OUT_DIR/lectio_mvp-$TS.sql.gz"
            # Keep 7 days of backups
            find "$OUT_DIR" -type f -name 'lectio_mvp-*.sql.gz' -mtime +7 -delete
            EOF
            chmod +x "$APP_DIR/bin/pg_backup.sh"
            # Add cron if not present
            (crontab -l 2>/dev/null | grep -q pg_backup.sh) || (crontab -l 2>/dev/null; echo "0 2 * * * bash $APP_DIR/bin/pg_backup.sh >> $APP_DIR/backups/backup.log 2>&1") | crontab -
